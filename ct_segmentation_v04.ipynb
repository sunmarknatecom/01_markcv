{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sunmarknatecom/01_markcv/blob/master/ct_segmentation_v04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA PREPROCESSING"
      ],
      "metadata": {
        "id": "eaDbnlDlL4c5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "882bcZe18hJk",
        "outputId": "c3650961-c681-4ec2-f121-b3d85f930563",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydicom\n",
            "  Downloading pydicom-2.2.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 13.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-2.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pydicom"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import the modules."
      ],
      "metadata": {
        "id": "KqNyHmQAf572"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configure the parameters."
      ],
      "metadata": {
        "id": "B3jiRLeQf0tZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0QpVtEvQ-gJa"
      },
      "outputs": [],
      "source": [
        "root = '/content/drive/MyDrive/segmentation/data/'\n",
        "idx_path = 'seg_006/'\n",
        "data_path = ['dicom/','image/','mask/','prediction/']\n",
        "train_idx = 'seg_001/'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the functions."
      ],
      "metadata": {
        "id": "GywjKQvGgo2m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Iz5F1I_J-ZLM"
      },
      "outputs": [],
      "source": [
        "from glob import glob\n",
        "import numpy as np\n",
        "import pydicom\n",
        "import cv2\n",
        "import os\n",
        "from pydicom.pixel_data_handlers.util import apply_modality_lut, apply_voi_lut\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, BatchNormalization, concatenate\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.losses import binary_crossentropy\n",
        "\n",
        "root = '/content/drive/MyDrive/segmentation/data/'\n",
        "idx_path = 'seg_006/'\n",
        "data_path = ['dicom/','image/','mask/','prediction/']\n",
        "\n",
        "class Annot_Mk():\n",
        "    '''\n",
        "    The class for segmentation\n",
        "    STEP1: transform the dicom file to jpg image file\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        self.root_path = '/content/drive/MyDrive/segmentation/data/'\n",
        "        self.idx_path = 'seg_006/'\n",
        "        self.data_path = ['dicom/','image/','mask/','prediction/']\n",
        "        self.window_center = -1400\n",
        "        self.window_width = 1300\n",
        "    # def dcm_to_img(src_img):\n",
        "    #     '''\n",
        "    #     src(1 param): dicom pixel nd array\n",
        "    #     return : float array [0-1]\n",
        "    #     requried package: numpy\n",
        "    #     cv2.normalize(src, dst[, alpha[, beta[, norm_type[, dtype[, mask]]]]]\t) ->\tdst\n",
        "    #     ex) cv2.normalize(src_img, None, 0, 255, cv2.NORM_MINMAX)\n",
        "    #     ref) https://docs.opencv.org/3.4/d2/de8/group__core__array.html#ga87eef7ee3970f86906d69a92cbf064bd\n",
        "    #     DEPRICATED...\n",
        "    #     '''\n",
        "    #     MAX_VAL = np.max(src_img)\n",
        "    #     MIN_VAL = np.min(src_img)\n",
        "    #     U_DIV = src_img - MIN_VAL\n",
        "    #     D_DIV = MAX_VAL - MIN_VAL\n",
        "    #     temp_img = U_DIV / D_DIV\n",
        "    #     scaled_img = 255 * temp_img\n",
        "    #     ret_img = np.array(scaled_img, dtype='uint8')\n",
        "    #     return ret_img\n",
        "    def raw_HU(self, path):\n",
        "        slice = pydicom.dcmread(path)\n",
        "        image = slice.pixel_array\n",
        "        return image\n",
        "    def set_HU(self, path, wnd_c = -1400, wnd_w = 1300):\n",
        "        '''\n",
        "        src(3 params): path is dcm file name, window_center(wnd_c), window_width(wnd_w)\n",
        "        return: window adjusted pixel_array\n",
        "        '''\n",
        "        slice = pydicom.dcmread(path)\n",
        "        b = int(slice.RescaleIntercept)\n",
        "        image = int(slice.RescaleSlope) * slice.pixel_array + b\n",
        "        slice.WindowCenter = wnd_c\n",
        "        slice.WindowWidth = wnd_w\n",
        "        image = apply_modality_lut(image, slice)\n",
        "        image2 = apply_voi_lut(image, slice)\n",
        "        image3 = np.clip(image2, wnd_c - (wnd_w/2), wnd_c + (wnd_w/2))\n",
        "        return image3\n",
        "    def dcm2jpg(self, wnd_c = -1400, wnd_w = 1300, wnd_o = True):\n",
        "        '''\n",
        "        USAGE:\n",
        "        C:>python dcm_to_jpg.py\n",
        "        '''\n",
        "        work_path = self.root_path + self.idx_path\n",
        "        if not os.path.exists(work_path + self.data_path[1]):\n",
        "            os.mkdir(work_path + self.data_path[1])  \n",
        "        LIST_FILES = sorted(glob(work_path + self.data_path[0] + \"*.dcm\"))\n",
        "        if wnd_o == True:\n",
        "            for i, elem in enumerate(LIST_FILES):\n",
        "                OBJ_ARR_WND = self.set_HU(path=elem, wnd_c=wnd_c, wnd_w=wnd_w)\n",
        "                # OBJ_ARRAY = dtj_cvt.dcm_to_img(OBJ_PIXEL)\n",
        "                OBJ_ARR_NRM = cv2.normalize(OBJ_ARR_WND, None, 0, 255, cv2.NORM_MINMAX)\n",
        "                OBJ_temp = OBJ_ARR_NRM.astype(np.uint8)\n",
        "                OBJ_IMG = cv2.cvtColor(OBJ_temp, cv2.COLOR_GRAY2RGB)\n",
        "                cv2.imwrite(work_path + self.data_path[1] + elem[-9:-3]+'jpg', OBJ_IMG)\n",
        "                progress = (\"]]] %3d\" %(int(round(100*i/len(LIST_FILES))))) + \"% completed.\"\n",
        "                print(progress, end='\\r')\n",
        "            print(progress)\n",
        "        elif wnd_o == False:\n",
        "            for i, elem in enumerate(LIST_FILES):\n",
        "                OBJ_ARR_WND = self.raw_HU(path=elem)\n",
        "                # OBJ_ARRAY = dtj_cvt.dcm_to_img(OBJ_PIXEL)\n",
        "                OBJ_ARR_NRM = cv2.normalize(OBJ_ARR_WND, None, 0, 255, cv2.NORM_MINMAX)\n",
        "                OBJ_temp = OBJ_ARR_NRM.astype(np.uint8)\n",
        "                OBJ_IMG = cv2.cvtColor(OBJ_temp, cv2.COLOR_GRAY2RGB)\n",
        "                cv2.imwrite(work_path + self.data_path[1] + elem[-9:-3]+'jpg', OBJ_IMG)\n",
        "                progress = (\"]]] %3d\" %(int(round(100*i/len(LIST_FILES))))) + \"% completed.\"\n",
        "                print(progress, end='\\r')\n",
        "            print(progress)\n",
        "        else:\n",
        "            pass\n",
        "    def input_img_data(self):\n",
        "        input_path = self.root_path + self.idx_path + self.data_path[1]\n",
        "        train_img_paths = sorted(glob(input_path +'*.jpg'))\n",
        "        train_imgs = np.array([cv2.resize(cv2.imread(path, cv2.IMREAD_UNCHANGED), (512,512)) for path in train_img_paths])\n",
        "        return train_imgs\n",
        "    def input_msk_data(self):\n",
        "        input_path = self.root_path + self.idx_path + self.data_path[2]\n",
        "        train_msk_paths = sorted(glob(input_path+'*.png'))\n",
        "        train_msks = np.array([cv2.resize(cv2.imread(path, cv2.IMREAD_GRAYSCALE), (512,512)) for path in train_msk_paths])\n",
        "        train_msks = train_msks.astype(np.float32)\n",
        "        train_msks = np.reshape(train_msks, (*train_msks.shape, 1))\n",
        "        train_msks -= 1\n",
        "        return train_msks\n",
        "    def unet_training(self):\n",
        "        inputs = Input((512, 512, 3))\n",
        "        bnorm1 = BatchNormalization()(inputs)\n",
        "        conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(bnorm1)\n",
        "        conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
        "        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "        conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
        "        conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
        "        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "        conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
        "        conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
        "        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "        conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
        "        conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
        "        pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "        conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
        "        conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
        "        up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
        "        conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
        "        conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
        "        up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
        "        conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
        "        conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
        "        up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
        "        conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
        "        conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
        "        up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
        "        conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
        "        conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
        "        conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
        "        model = Model(inputs=[inputs], outputs=[conv10])\n",
        "        SMOOTH = 1.\n",
        "        def dice_coef(y_true, y_pred):\n",
        "            y_true_f = K.flatten(y_true)\n",
        "            y_pred_f = K.flatten(y_pred)\n",
        "            intersection = K.sum(y_true_f * y_pred_f)\n",
        "            return (2. * intersection + SMOOTH) / (K.sum(y_true_f) + K.sum(y_pred_f) + SMOOTH)\n",
        "        def bce_dice_loss(y_true, y_pred):\n",
        "            return 0.5 * binary_crossentropy(y_true, y_pred) - dice_coef(y_true, y_pred)\n",
        "        model.compile(Adam(learning_rate=1e-4), bce_dice_loss, metrics=[binary_crossentropy, dice_coef])\n",
        "        model.fit(train_imgs[50:], train_msks[50:], batch_size=12, epochs=5, validation_data=(train_imgs[:50], train_msks[:50]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "obj = Annot_Mk()"
      ],
      "metadata": {
        "id": "_bCNrnGfs6dq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "81bEg0fG8IM2",
        "outputId": "6fb26e5a-396b-4684-c4bf-1bb2eef2360a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "]]] 100% completed.\n"
          ]
        }
      ],
      "source": [
        "obj.dcm2jpg(wnd_o=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list = sorted(os.listdir('/content/drive/MyDrive/segmentation/data/seg_006/image'))"
      ],
      "metadata": {
        "id": "7GLtdhQKzWaV"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list"
      ],
      "metadata": {
        "id": "0i5XZlp7zizc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img2 = cv2.imread(+list[0], cv2.IMREAD_UNCHANGED)"
      ],
      "metadata": {
        "id": "tL_0YGQJzBc1"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img2"
      ],
      "metadata": {
        "id": "RBRMKBZxzKsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNR8ySk9G93x"
      },
      "outputs": [],
      "source": [
        "list = sorted(os.listdir('/content/drive/MyDrive/segmentation/data/seg_006/image'))\n",
        "for elem in list:\n",
        "    img = cv2.imread('/content/drive/MyDrive/segmentation/data/seg_006/image/'+elem, cv2.IMREAD_UNCHANGED)\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confirm the GPU."
      ],
      "metadata": {
        "id": "W32vqj31g_Qk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8O76RBiWmC9T"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    raise SystemError(\"GPU device not found\")\n",
        "print(\"Found GPU at: {}\".format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsLB3C3yi25V"
      },
      "outputs": [],
      "source": [
        "train_img_paths = sorted(glob(root + train_idx + data_path[1] + '*.jpg'))\n",
        "train_msk_paths = sorted(glob(root + train_idx + data_path[2] + '*.png'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_ASJ3Qb6uni"
      },
      "outputs": [],
      "source": [
        "train_imgs = np.array([cv2.resize(cv2.imread(path, cv2.IMREAD_UNCHANGED), (512,512)) for path in train_img_paths])\n",
        "train_msks = np.array([cv2.resize(cv2.imread(path, cv2.IMREAD_GRAYSCALE), (512,512)) for path in train_msk_paths])\n",
        "\n",
        "train_msks = train_msks.astype(np.float32)\n",
        "train_msks = np.reshape(train_msks, (*train_msks.shape, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-A1zt2KR_21E"
      },
      "outputs": [],
      "source": [
        "train_msks -= 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEH4I4ganEg0"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "fig = plt.figure(0, figsize=(20, 20))\n",
        "fig.add_subplot(1, 2, 1)\n",
        "plt.imshow(train_imgs[0])\n",
        "fig.add_subplot(1, 2, 2)\n",
        "plt.imshow(np.squeeze(train_msks[0]), cmap='gray')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3H1M59pti8id"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, BatchNormalization, concatenate\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "inputs = Input((512, 512, 3))\n",
        "bnorm1 = BatchNormalization()(inputs)\n",
        "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(bnorm1)\n",
        "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
        "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
        "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
        "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
        "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
        "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
        "conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
        "pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
        "conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
        "conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
        "conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
        "\n",
        "up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
        "conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
        "conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
        "\n",
        "up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
        "conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
        "conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
        "\n",
        "up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
        "conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
        "conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
        "\n",
        "conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
        "\n",
        "model = Model(inputs=[inputs], outputs=[conv10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCyGwtVP7omy"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "from keras.losses import binary_crossentropy\n",
        "\n",
        "SMOOTH = 1.\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + SMOOTH) / (K.sum(y_true_f) + K.sum(y_pred_f) + SMOOTH)\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return 0.5 * binary_crossentropy(y_true, y_pred) - dice_coef(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model.compile(Adam(learning_rate=1e-4), bce_dice_loss, metrics=[binary_crossentropy, dice_coef])\n",
        "\n",
        "model.fit(train_imgs[50:], train_msks[50:], batch_size=12, epochs=5, validation_data=(train_imgs[:50], train_msks[:50]))"
      ],
      "metadata": {
        "id": "Rgxh4y3Vgb-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_list = sorted(glob(root + idx_path + data_path[1] + '*.jpg'))\n",
        "predic = []\n",
        "\n",
        "for elem in file_list:\n",
        "    img_obj = cv2.imread(elem, cv2.IMREAD_UNCHANGED)\n",
        "    predic.append(img_obj)\n",
        "\n",
        "prediction = np.array(predic)"
      ],
      "metadata": {
        "id": "cvxZQLvINno4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXQ7eYEtBTCJ"
      },
      "outputs": [],
      "source": [
        "pred_img = model.predict(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXgYkgawhv2W"
      },
      "outputs": [],
      "source": [
        "temp_pred = []\n",
        "\n",
        "for elem in pred_img:\n",
        "    bgr_img = cv2.cvtColor(elem, cv2.COLOR_GRAY2RGB)\n",
        "    temp_pred.append(bgr_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGNfp4MhX9Ys"
      },
      "outputs": [],
      "source": [
        "for i, img in enumerate(temp_pred):\n",
        "    path_ = '/content/drive/MyDrive/segmentation/data/seg_006/mask/mask_1-%03d.png'%(i+1)\n",
        "    img = img * 255\n",
        "    cv2.imwrite(path_, img)\n",
        "    plt.imshow(img)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlrd4o--cdN6"
      },
      "outputs": [],
      "source": [
        "temp_2_pred = []\n",
        "for elem in temp_pred:\n",
        "    elem[elem<0.5] = 0\n",
        "    elem[elem>=0.5] = 1\n",
        "    elem.astype('uint8')\n",
        "    temp_2_pred.append(elem)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zf9WxcyIB-FY"
      },
      "outputs": [],
      "source": [
        "for i, elem in enumerate(temp_2_pred):\n",
        "    path = '/content/drive/MyDrive/Seg_Data/result/result_%03d.png'%(i+1)\n",
        "    cv2.imwrite(path, elem)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "ct_segmentation_v04.ipynb",
      "provenance": [],
      "mount_file_id": "1DbIERfiPIGhE6UAE90FvVvJ5C7KP3ahD",
      "authorship_tag": "ABX9TyOk5jFhMF+XkwRZc1Wm9EQ7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}